{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e88ca-9759-4003-9450-4066bf58478d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.74.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/alan/miniconda3/lib/python3.13/site-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: packaging in /home/alan/miniconda3/lib/python3.13/site-packages (from tensorboard) (25.0)\n",
      "Collecting pillow (from tensorboard)\n",
      "  Using cached pillow-11.3.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/alan/miniconda3/lib/python3.13/site-packages (from tensorboard) (6.31.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/alan/miniconda3/lib/python3.13/site-packages (from tensorboard) (72.1.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/alan/miniconda3/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading grpcio-1.74.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached pillow-11.3.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "Installing collected packages: werkzeug, tensorboard-data-server, pillow, markdown, grpcio, absl-py, tensorboard\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [tensorboard]\u001b[0m [tensorboard]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 grpcio-1.74.0 markdown-3.8.2 pillow-11.3.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 werkzeug-3.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorboard \n",
    "pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463b5501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "PositionEncoding(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nvme/appdata/code/workspace/kubeflow_pipeline/ajperry_pipeline/ml/models/transformer.py:115: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n",
      "  torch.nn.init.xavier_uniform(p)\n",
      "Processing epoch: 0: 100%|██████████| 47/47 [00:05<00:00,  8.77it/s, loss=4.784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Source:\t['I hate it.']\n",
      "Target:\t[\"year number in all music videos is waaaay worse, you cannot escape it, especially in 2000's songs for some reason\"]\n",
      "Predicted:\t\n",
      "--------------------------------------------------------------------------------\n",
      "Source:\t['‘The Toxic Avenger’ Review: Peter Dinklage Crushes It While Crushing Heads']\n",
      "Target:\t['I thought Peter Dinklage was just doing the voice.']\n",
      "Predicted:\t\n",
      "--------------------------------------------------------------------------------\n",
      "Source:\t['How would you feel about your partner waking you up just to have sex?']\n",
      "Target:\t['Happened 2 times, loved both. I have actively told her she can wake me literally any time for that. She has actively told me not to wake her under any circumstances, she loves her sleep.']\n",
      "Predicted:\t\n",
      "--------------------------------------------------------------------------------\n",
      "Source:\t['What do you think is the single biggest mistake in movie history?']\n",
      "Target:\t['The Conqueror (1956).\\n\\nDecision was made to film downwind of a Nuclear testing site.\\n\\n41% of the entire cast & crew ended up developing cancer.\\n\\nPedro Armendariz was one of the actors. He was diagnosed with terminal neck cancer and chose to appear in the Bond movie \"From Russia With Love\" during his cancer treatment to help secure his family\\'s financial future. The pain eventually got too great for him though and he took his own life shortly after filming.']\n",
      "Predicted:\t\n",
      "--------------------------------------------------------------------------------\n",
      "Source:\t['Most US neurologists prescribing MS drugs have received pharma industry cash | Nearly 80% of US neurologists prescribing drugs for multiple sclerosis (MS) received at least one pharma industry payment, with higher volume prescribers more likely to be beneficiaries, 5 year study finds']\n",
      "Target:\t['As a physician I can maybe shed some light on this.  I\\'m a pulmonologist, received maybe about $1500 in my lifetime from pharma.  None in cash, just lunch and dinners.  They might bring lunch for the entire clinic staff or trainees.  They might host a dinner session where an expert will speak on the subject while we attend, ask questions, and get a free dinner.  It adds up over the years.  Lunch might be $20-30 while dinner might be a bit more.   It can add up to a few hundred per year and over several years it can certainly add up to the thousands.  The ones that are in the tens of thousands or hundreds of thousands are not because they\\'re getting kickbacks for prescribing, it\\'s usually some combination of consulting fees and/or flying them out to give talks.  So it\\'s not hard to imagine if theres some renounced expert who strongly believes in the drug would be willing to give educational talks to other neurologists about it.  If they get flown out, their travel, hotel, food, and speaking fee will be paid for.   That usually amounts to fees in the tens of thousands range over several years.  The ones getting 100k+ are most likely to be in the form of research grants or consulting fees.  A research grant can easily be 100k for each individual grant.  Thats just the reality of things.  And while all this seems sketch to outsiders, I think there is some benefit to us attending these dinners and educational sessions.  If theres new medications that actually work well and we\\'re interested in prescribing them, we can pick the brains of these experts who are actually using it as well as the manufacturers themselves can guide us on how to get it through insurances.   In my field, I was prescribing biologics for asthma.  A new one came out a few years ago that I thought was fantastic on paper, could help alot of people for whom the other biologics weren\\'t working. Theres some benefit in attending a dinner to ask them questions about the logics of administration, teaching, insurance coverage, dosing, certain adverse events to look for, etc. And of course for some of the more basic meds like inhalers they often give free samples which we\\'re constantly giving them away to patients, preferably ones that are really tight on budget.  I may give them samples to see if a certain inhaler works well for them before making them pay hundreds every month to maintain it. It\\'s easy to say, \"doctors are getting their pockets lined by big pharma\" and get clicks but the reality is 99% of docs are just ordinary people who genuinely want to learn about the drug while also having a nice dinner with colleagues and de-stress a bit.  Theres certainly bad apples out there, but thats the case with anything.']\n",
      "Predicted:\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epoch: 1:  51%|█████     | 24/47 [00:02<00:02,  9.43it/s, loss=6.224]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01majperry_pipeline\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreddit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[32m      2\u001b[39m config = {\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m8\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnum_epochs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m500\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnum_examples\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m5\u001b[39m,\n\u001b[32m     14\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nvme/appdata/code/workspace/kubeflow_pipeline/ajperry_pipeline/ml/utils/reddit.py:124\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m    121\u001b[39m batch_iterator = tqdm(train_dataloader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batch_iterator:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     encoder_input = \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoder_input\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# b, seq_len\u001b[39;00m\n\u001b[32m    125\u001b[39m     decoder_input = batch[\u001b[33m\"\u001b[39m\u001b[33mdecoder_input\u001b[39m\u001b[33m\"\u001b[39m].to(device) \u001b[38;5;66;03m# b, seq_len\u001b[39;00m\n\u001b[32m    126\u001b[39m     encoder_mask = batch[\u001b[33m\"\u001b[39m\u001b[33mencoder_mask\u001b[39m\u001b[33m\"\u001b[39m].to(device) \u001b[38;5;66;03m# b, 1, 1, seq_len\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from ajperry_pipeline.ml.utils.reddit import train\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 8,\n",
    "    \"num_epochs\": 500,\n",
    "    \"lr\": 1e-4,\n",
    "    \"seq_len\": 560,\n",
    "    \"d_model\": 512,\n",
    "    \"model_folder\": \"weights\",\n",
    "    \"model_basename\": \"tmodel_\",\n",
    "    \"preload\": None,\n",
    "    \"tokenizer_file\": \"tokenizer_{0}.json\",\n",
    "    \"experiment_name\": \"runs/tmodel\",\n",
    "    \"num_examples\": 5,\n",
    "}\n",
    "train(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
