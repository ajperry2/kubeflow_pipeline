{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e1e88ca-9759-4003-9450-4066bf58478d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /home/alan/miniconda3/lib/python3.13/site-packages (2.20.0)\n",
      "Collecting torchtext\n",
      "  Downloading torchtext-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/alan/miniconda3/lib/python3.13/site-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/alan/miniconda3/lib/python3.13/site-packages (from tensorboard) (1.74.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/alan/miniconda3/lib/python3.13/site-packages (from tensorboard) (3.8.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/alan/miniconda3/lib/python3.13/site-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: packaging in /home/alan/miniconda3/lib/python3.13/site-packages (from tensorboard) (25.0)\n",
      "Requirement already satisfied: pillow in /home/alan/miniconda3/lib/python3.13/site-packages (from tensorboard) (11.3.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/alan/miniconda3/lib/python3.13/site-packages (from tensorboard) (6.31.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/alan/miniconda3/lib/python3.13/site-packages (from tensorboard) (72.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/alan/miniconda3/lib/python3.13/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/alan/miniconda3/lib/python3.13/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: tqdm in /home/alan/miniconda3/lib/python3.13/site-packages (from torchtext) (4.67.1)\n",
      "Requirement already satisfied: requests in /home/alan/miniconda3/lib/python3.13/site-packages (from torchtext) (2.32.5)\n",
      "Requirement already satisfied: torch in /home/alan/miniconda3/lib/python3.13/site-packages (from torchtext) (2.8.0)\n",
      "Requirement already satisfied: six in /home/alan/miniconda3/lib/python3.13/site-packages (from torchtext) (1.17.0)\n",
      "Collecting sentencepiece (from torchtext)\n",
      "  Downloading sentencepiece-0.2.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/alan/miniconda3/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/alan/miniconda3/lib/python3.13/site-packages (from requests->torchtext) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/alan/miniconda3/lib/python3.13/site-packages (from requests->torchtext) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/alan/miniconda3/lib/python3.13/site-packages (from requests->torchtext) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alan/miniconda3/lib/python3.13/site-packages (from requests->torchtext) (2025.8.3)\n",
      "Requirement already satisfied: filelock in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/alan/miniconda3/lib/python3.13/site-packages (from torch->torchtext) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/alan/miniconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch->torchtext) (1.3.0)\n",
      "Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
      "Downloading sentencepiece-0.2.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, torchtext\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torchtext]\n",
      "\u001b[1A\u001b[2KSuccessfully installed sentencepiece-0.2.1 torchtext-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorboard torchtext \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d31c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463b5501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "PositionEncoding(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nvme/appdata/code/workspace/kubeflow_pipeline/ajperry_pipeline/ml/models/transformer.py:120: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n",
      "  torch.nn.init.xavier_uniform(p)\n",
      "Processing epoch: 0:  57%|█████▋    | 27/47 [00:03<00:02,  8.85it/s, loss=5.904]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01majperry_pipeline\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreddit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[32m      3\u001b[39m config = {\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m8\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnum_epochs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m500\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnum_examples\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m5\u001b[39m,\n\u001b[32m     15\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nvme/appdata/code/workspace/kubeflow_pipeline/ajperry_pipeline/ml/utils/reddit.py:187\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m    182\u001b[39m decoder_output = model.decode(\n\u001b[32m    183\u001b[39m     encoder_output, encoder_mask, decoder_input, decoder_mask\n\u001b[32m    184\u001b[39m )  \u001b[38;5;66;03m# b, seq_len, d_model\u001b[39;00m\n\u001b[32m    185\u001b[39m proj_output = model.project(decoder_output)\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m label = \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# b, seq_len\u001b[39;00m\n\u001b[32m    189\u001b[39m loss = loss_fn(\n\u001b[32m    190\u001b[39m     proj_output.view(-\u001b[32m1\u001b[39m, train_dataset.output_tokenizer.get_vocab_size()),\n\u001b[32m    191\u001b[39m     label.view(-\u001b[32m1\u001b[39m),\n\u001b[32m    192\u001b[39m )\n\u001b[32m    193\u001b[39m batch_iterator.set_postfix({\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m6.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m})\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from ajperry_pipeline.ml.utils.reddit import train\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 8,\n",
    "    \"num_epochs\": 500,\n",
    "    \"lr\": 1e-4,\n",
    "    \"seq_len\": 560,\n",
    "    \"d_model\": 512,\n",
    "    \"model_folder\": \"weights\",\n",
    "    \"model_basename\": \"tmodel_\",\n",
    "    \"preload\": None,\n",
    "    \"tokenizer_file\": \"tokenizer_{0}.json\",\n",
    "    \"experiment_name\": \"runs/tmodel\",\n",
    "    \"num_examples\": 5,\n",
    "    \"verbose\": False,\n",
    "}\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7da347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.46576884437471344\n"
     ]
    }
   ],
   "source": [
    "import torchtext.data.metrics as metrics\n",
    "\n",
    "# Example candidate translations (can have different lengths)\n",
    "candidate_corpus = [\n",
    "    [\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"],\n",
    "    [\"a\", \"squirrel\", \"is\", \"eating\", \"a\", \"nut\"],\n",
    "]\n",
    "\n",
    "# Example reference translations (each candidate can have multiple references, also of varying lengths)\n",
    "references_corpus = [\n",
    "    [[\"there\", \"is\", \"a\", \"cat\", \"on\", \"the\", \"mat\"]],\n",
    "    [[\"a\", \"squirrel\", \"is\", \"eating\", \"a\", \"tasty\", \"nut\"]],\n",
    "]\n",
    "\n",
    "# Calculate BLEU score with max_n=4 (for unigrams, bigrams, trigrams, and 4-grams)\n",
    "bleu_score = metrics.bleu_score(candidate_corpus, references_corpus, max_n=4)\n",
    "print(f\"BLEU Score: {bleu_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_score = metrics.bleu_score(candidate_corpus, references_corpus, max_n=4)\n",
    "print(f\"BLEU Score: {bleu_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
